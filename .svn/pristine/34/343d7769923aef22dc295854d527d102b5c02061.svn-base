//
//  CCRecordAssetWriter.m
//  AV_Demo
//
//  Created by chencheng on 2019/3/19.
//  Copyright © 2019年 chen. All rights reserved.
//

#import "CCRecordAssetWriter.h"

#define CCRecordWeakSelf(weakSelf) __weak typeof(self) weakSelf = self;
#define CCRecordStrongSelf(strongSelf) __strong typeof(weakSelf) strongSelf = weakSelf;

@interface CCRecordAssetWriter ()<AVCaptureVideoDataOutputSampleBufferDelegate,AVCaptureAudioDataOutputSampleBufferDelegate>
{
    BOOL _canWrite;
    NSURL *_currentURL;
    CGFloat _videoWidth;
    CGFloat _videoHeight;
}

/* 设备输出时需要保证在同一个线程内*/
@property(nonatomic,strong) dispatch_queue_t recordQueue;
@property(nonatomic,strong) AVCaptureVideoDataOutput *videoOutput;
@property(nonatomic,strong) AVCaptureAudioDataOutput *audioOutput;
@property(nonatomic,strong) AVCaptureConnection *connection;

@property(nonatomic,strong) AVAssetWriter *assetWriter;
@property(nonatomic,strong) AVAssetWriterInput *assetWriterVideoInput;
@property(nonatomic,strong) AVAssetWriterInput *assetWriterAudioInput;

@property(nonatomic,strong) NSDictionary *videoWriterSetting;
@property(nonatomic,strong) NSDictionary *audioWriterSetting;

@end

@implementation CCRecordAssetWriter

#pragma mark - Super
- (void)startRunning {    
    if (self.type & CCRecordTypeVideo) {
        [self addDeviceInput:self.videoInput];
        [self addDeviceOutput:self.videoOutput];
        self.connection.videoOrientation = self.previewLayer.connection.videoOrientation;
    }
    if (self.type % CCRecordTypeAudio) {
        [self addDeviceInput:self.audioInput];
        [self addDeviceOutput:self.audioOutput];
    }
    
    [self.session startRunning];
    
    _videoWidth = CGRectGetWidth(self.containerView.bounds);
    _videoHeight = CGRectGetHeight(self.containerView.bounds);
}

- (void)stopRunning {
    [self stopRunning];
    [self.session stopRunning];
}

- (void)startRecording {
    if (!self.coverSave) {
        if (![CCRecordTool checkFileIfEligible:self.fileURL.path]) {
            NSLog(@"该路径已有其他文件，无法进行录制.");
            return;
        }
    }
    
    CCRecordWeakSelf(weakSelf)
    dispatch_async(self.recordQueue, ^{
        CCRecordStrongSelf(strongSelf)
        strongSelf->_canWrite = YES;
        if (!self.assetWriter) {
            [self initializedAssetWriter];
        }
        if (self.status == CCRecordStatusPause) {
            self.status = CCRecordStatusRecording;
            return; //恢复录制
        }
        
        self.status = CCRecordStatusRecording;
        if (self.startRecordBlock) self.startRecordBlock(strongSelf->_currentURL);
    });
}

- (void)pauseRecording {
    dispatch_async(self.recordQueue, ^{
        self.status = CCRecordStatusPause;
        [self stopRecording];
    });
}

- (void)stopRecording {
    CCRecordWeakSelf(weakSelf)
    dispatch_async(self.recordQueue, ^{
        CCRecordStrongSelf(strongSelf)
        strongSelf->_canWrite = NO;
        NSURL *url = strongSelf->_currentURL;
        if (![self.videoArr containsObject:url] && url) {
            [self.videoArr addObject:url];
        }
//        self stopw
    });
}

- (void)finishRecording {
    self.status = CCRecordStatusFinish;
    [self stopRecording];
}

#pragma mark - Delegate
//在这里可以获取视频帧、实现滤镜效果
- (void)captureOutput:(AVCaptureOutput *)output didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer fromConnection:(AVCaptureConnection *)connection {
    if (sampleBuffer == NULL) {
        NSLog(@"empty sampleBuffer");
        return;
    }
    if (_canWrite == NO) return;
    
    if (connection == [_videoOutput connectionWithMediaType:AVMediaTypeVideo]) {
        if (self.videoImageBlock) {
            UIImage *image = [self imageFromSampleBuffer:sampleBuffer];
            self.videoImageBlock(image);
        }
        if (self.videoDataBlock) {
            UIImage *image = [self imageFromSampleBuffer:sampleBuffer];
            NSData *data = UIImageJPEGRepresentation(image, 0.9f);
            self.videoDataBlock(data);
        }
        if (self.sampleBufferRefBlock) self.sampleBufferRefBlock(sampleBuffer);
        
        if (_assetWriter == nil) {
            NSLog(@"assetWriter为空.");
            [self destoryWriter];
            return;
        }
        if (_assetWriter.status == AVAssetWriterStatusFailed) {
            NSLog(@"Error: %@",_assetWriter.error.localizedDescription);
            [self stopWrite];
            return;
        }
        if (_assetWriter.status == AVAssetWriterStatusUnknown) {
            NSLog(@"开始写入...");
            [_assetWriter startWriting];
            [_assetWriter startSessionAtSourceTime:CMSampleBufferGetPresentationTimeStamp(sampleBuffer)];
        }
        if (_assetWriterVideoInput.readyForMoreMediaData) {
            BOOL success = [_assetWriterVideoInput appendSampleBuffer:sampleBuffer];    //如果报错请检查路径是否已存在文件
            if (!success) {
                NSLog(@"Video append SampleBuffer fail!");
                @synchronized (self) {
                    [self stopRecording];
                }
            }
        }
    }
    
    if (connection == [_audioOutput connectionWithMediaType:AVMediaTypeAudio]) {
        if (self.assetWriterAudioInput.readyForMoreMediaData) {
            BOOL success = [_assetWriterAudioInput appendSampleBuffer:sampleBuffer];
            if (!success) {
                NSLog(@"Audio append sampleBuffer fail!");
                @synchronized (self) {
                    [self stopRecording];
                }
            }
        }
    }

}

#pragma mark - APIs (private)
- (void)initializedAssetWriter {
    if (self.videoArr.count == 0) {
        [self cancelRecord];
    }
    
    _currentURL = [self availableFileURLToTmp];
    unlink([_currentURL.path UTF8String]);
    unlink([self.fileURL.path UTF8String]);
    NSLog(@"获取到可用的文件路径: %@",_currentURL.path);
    
    self.status = CCRecordStatusNone;
    
    if (self.type & CCRecordTypeVideo) {
        if ([self.assetWriter canAddInput:self.assetWriterVideoInput]) {
            [self.assetWriter addInput:self.assetWriterVideoInput];
        }
    }
    if (self.type & CCRecordTypeAudio) {
        if ([self.assetWriter canAddInput:self.assetWriterAudioInput]) {
            [self.assetWriter addInput:self.assetWriterAudioInput];
        }
    }
}

- (void)stopWrite {
    dispatch_async(self.recordQueue, ^{
        if (self.assetWriter) {
            CCRecordWeakSelf(weakSelf)
            [self.assetWriter finishWritingWithCompletionHandler:^{
                [weakSelf destoryWriter];
            }];
        }else {
            NSLog(@"writer对象为空.");
        }
        
        if (self.status == CCRecordStatusPause) {
            if (self.pauseRecordBlock) self.pauseRecordBlock(self.fileURL);
        }
        if (self.status == CCRecordStatusFinish) {
            [super finishRecording];
        }
    });
}

- (void)destoryWriter {
    dispatch_async(self.recordQueue, ^{
        @synchronized (self) {
            self.assetWriter = nil;
            self.assetWriterVideoInput = nil;
            self.assetWriterAudioInput = nil;
            self.status = CCRecordStatusNone;
            NSLog(@"destory writer.");
        }
    });
}

- (UIImage *)imageFromSampleBuffer:(CMSampleBufferRef)sampleBuffer {
    // 为媒体数据设置一个CMSampleBuffer的Core Video图像缓存对象
    CVImageBufferRef imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer);
    
    // 锁定pixel buffer的基地址
    CVPixelBufferLockBaseAddress(imageBuffer, 0);
    // 得到pixel buffer的基地址
    void *baseAddress = CVPixelBufferGetBaseAddress(imageBuffer);
    // 得到pixel buffer的行字节数
    size_t bytesPerRow = CVPixelBufferGetBytesPerRow(imageBuffer);
    // 得到pixel buffer的宽和高
    size_t width = CVPixelBufferGetWidth(imageBuffer);
    size_t height = CVPixelBufferGetHeight(imageBuffer);
    // 创建一个依赖于设备的RGB颜色空间
    CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB();
    // 用抽样缓存的数据创建一个位图格式的图形上下文（graphics context）对象
    CGContextRef context = CGBitmapContextCreate(baseAddress, width, height, 8, bytesPerRow, colorSpace, kCGBitmapByteOrder32Little | kCGImageAlphaPremultipliedFirst);
    // 根据这个位图context中的像素数据创建一个Quartz image对象
    CGImageRef quartzImage = CGBitmapContextCreateImage(context);
    // 解锁pixel buffer
    CVPixelBufferUnlockBaseAddress(imageBuffer,0);
    // 释放context和颜色空间
    CGContextRelease(context); CGColorSpaceRelease(colorSpace);
    // 用Quartz image创建一个UIImage对象image
    UIImage *image = [UIImage imageWithCGImage:quartzImage scale:1 orientation:UIImageOrientationUp];
    // 释放Quartz image对象
    CGImageRelease(quartzImage);
    return (image);
}

#pragma mark - Lazy load
- (dispatch_queue_t)recordQueue {
    if (!_recordQueue) {
        _recordQueue = dispatch_queue_create("ccrecord_media_writer", DISPATCH_QUEUE_SERIAL);
    }
    return _recordQueue;
}

- (AVCaptureVideoDataOutput *)videoOutput {
    if (!_videoOutput) {
        _videoOutput = [[AVCaptureVideoDataOutput alloc] init];
        _videoOutput.alwaysDiscardsLateVideoFrames = YES;   //立即丢弃旧帧，节省内存
        //这里遇到个坑，在解析每帧数据的时候一直报CGBitmapContextCreate相关错误，加上下面代码就可以了，具体参考https://www.jianshu.com/p/61ca3a917fe5
        NSDictionary *videoSettings = @{(id)kCVPixelBufferPixelFormatTypeKey:@(kCVPixelFormatType_32BGRA)};
        [_videoOutput setVideoSettings:videoSettings];
        [_videoOutput setSampleBufferDelegate:self queue:self.recordQueue];
    }
    return _videoOutput;
}

- (AVCaptureAudioDataOutput *)audioOutput {
    if (!_audioOutput) {
        _audioOutput = [[AVCaptureAudioDataOutput alloc] init];
        [_audioOutput setSampleBufferDelegate:self queue:self.recordQueue];
    }
    return _audioOutput;
}

- (AVCaptureConnection *)connection {
    if (!_connection) {
        _connection = [self.videoOutput connectionWithMediaType:AVMediaTypeVideo];
        if (_connection.isVideoStabilizationSupported) {
            _connection.preferredVideoStabilizationMode = AVCaptureVideoStabilizationModeAuto;
        }
    }
    return _connection;
}

- (AVAssetWriterInput *)assetWriterVideoInput {
    if (!_assetWriterVideoInput) {
        _assetWriterVideoInput = [AVAssetWriterInput assetWriterInputWithMediaType:AVMediaTypeVideo outputSettings:self.videoWriterSetting];
        _assetWriterVideoInput.expectsMediaDataInRealTime = YES;    //设为YES，否则会丢帧
    }
    return _assetWriterVideoInput;
}

- (AVAssetWriterInput *)assetWriterAudioInput {
    if (!_assetWriterAudioInput) {
        _assetWriterAudioInput = [AVAssetWriterInput assetWriterInputWithMediaType:AVMediaTypeAudio outputSettings:self.audioWriterSetting];
        _assetWriterAudioInput.expectsMediaDataInRealTime = YES;
    }
    return _assetWriterAudioInput;
}

- (NSDictionary *)videoWriterSetting {
    CGFloat videoWidth = _videoWidth;
    CGFloat videoHeight = _videoHeight;
    
    NSInteger numPixels = videoWidth * videoHeight; //写入视频大小
    
    //每像素比特
    CGFloat bitsPerPixel = 6.0f;
    NSInteger bitsPerSecond = numPixels * bitsPerPixel;
    
    /*
     码率和帧率设置
     AVVideoCodecKey 编码方式：H.264编码
     AVVideoExpectedSourceFrameRateKey 帧率：每秒钟多少帧画面
     AVVideoAverageBitRateKey 码率：单位时间内保存的数据量,码率: 编码效率, 码率越高,则画面越清晰, 如果码率较低会引起马赛克 --> 码率高有利于还原原始画面,但是也不利于传输)
     AVVideoMaxKeyFrameIntervalKey 关键帧（GOPsize)间隔：多少帧为一个GOP,
     */
    NSDictionary *compressionProperties = @{AVVideoAverageBitRateKey: @(bitsPerSecond),
                                            AVVideoExpectedSourceFrameRateKey: @(30),
                                            AVVideoMaxKeyFrameIntervalKey: @(30),
                                            AVVideoProfileLevelKey: AVVideoProfileLevelH264BaselineAutoLevel,
                                            };
    return @{AVVideoCodecKey: AVVideoCodecH264,
             AVVideoScalingModeKey: AVVideoScalingModeResizeAspectFill,
             AVVideoWidthKey: @(videoWidth),
             AVVideoHeightKey: @(videoHeight),
             AVVideoCompressionPropertiesKey: compressionProperties,
             };
}

- (NSDictionary *)audioWriterSetting {
    return @{AVEncoderBitRatePerChannelKey: @(28000),
             AVFormatIDKey: @(kAudioFormatMPEG4AAC),
             AVNumberOfChannelsKey: @(1),
             AVSampleRateKey: @(22050),
             };
}

@end
